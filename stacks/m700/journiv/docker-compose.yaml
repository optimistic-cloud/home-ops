x-common-valkey-env: &common-valkey-env
  REDIS_URL: redis://valkey:6379/0
  CELERY_BROKER_URL: redis://valkey:6379/0
  CELERY_RESULT_BACKEND: redis://valkey:6379/0

x-celery-common: &celery-common
  image: swalabtech/journiv-app:${APP_VERSION:-latest}
  env_file: .env
  volumes:
    - ./data:/data
  environment:
    DB_DRIVER: sqlite
    DATABASE_URL: sqlite:////data/journiv.db
  depends_on:
    valkey:
      condition: service_healthy
  networks:
    - backend
  restart: unless-stopped
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "5"
  deploy:
    resources:
      limits:
        cpus: "1.0"
        memory: 1g
      reservations:
        memory: 256m

x-app-common: &app-common
  image: swalabtech/journiv-app:${APP_VERSION:-latest}
  env_file: .env
  volumes:
    - journiv-data:/data
  environment:
    DB_DRIVER: sqlite
    DATABASE_URL: sqlite:////data/journiv.db
  depends_on:
    valkey:
      condition: service_healthy
  networks:
    - backend
  restart: unless-stopped
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "5"

x-celery-healthcheck: &celery-healthcheck
  interval: 30s
  timeout: 10s
  retries: 5
  start_period: 40s

services:
  # Journiv uses Valkey which is similar to Redis for cache.
  valkey:
    image: valkey/valkey:9.0-alpine
    container_name: journiv-valkey-cache
    restart: unless-stopped
    volumes:
      - ./data/valkey:/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  celery-worker:
    <<: *celery-common
    container_name: journiv-celery-worker
    command: celery -A app.core.celery_app worker --loglevel=info
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: celery-worker
      ENVIRONMENT: production
    healthcheck:
      <<: *celery-healthcheck

  celery-beat:
    <<: *celery-common
    container_name: journiv-celery-beat
    command: celery -A app.core.celery_app beat --loglevel=info --scheduler redbeat.RedBeatScheduler --pidfile=/tmp/celerybeat.pid
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: celery-beat
      ENVIRONMENT: production
      REDBEAT_REDIS_URL: redis://valkey:6379/2
    healthcheck:
      <<: *celery-healthcheck

  journiv-init:
    image: alpine:3.23.3@sha256:25109184c71bdad752c8312a8623239686a9a2071e8825f20acb8f2198c3f659
    volumes:
      - journiv-data:/data
    command: |
      sh -c "
        chown -R 1000:1000 /data &&
        chmod -R 700 /data
      "
    restart: "no"

  journiv-app:
    <<: *app-common
    container_name: journiv-sqlite-app
    ports:
      - "${APP_PORT:-8000}:8000"
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: app
      ENVIRONMENT: production
      RATE_LIMIT_STORAGE_URI: redis://valkey:6379/1
    networks:
      - backend
      - frontend
      - m700_default
    healthcheck:
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2g
        reservations:
          memory: 512m

  admin-cli:
    <<: *app-common
    container_name: journiv-sqlite-admin-cli
    profiles: ["admin"]
    command: ["sleep", "infinity"]
    environment:
      <<: *common-valkey-env
      SERVICE_ROLE: admin-cli
      ENVIRONMENT: production
    # No healthcheck needed for idle container
    healthcheck:
      disable: true
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1g
        reservations:
          memory: 256m

networks:
  backend:
    driver: bridge
  frontend:
    driver: bridge
  m700_default:
    external: true

volumes:
  journiv-data:
    name: journiv-data